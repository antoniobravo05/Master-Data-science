cars
view(cars)
View(cars)
#Vamos a intentar dada una distancia, calcular una velocidad.
#En R la funcion que permite crear un modelo linal es "lm". Ver ayuda
#lm(variables a predecir~variables predictoras,datos,)
lm(speed~dist,data=cars)
#Vamos a intentar dada una distancia, calcular una velocidad.
#En R la funcion que permite crear un modelo linal es "lm". Ver ayuda
#lm(variables a predecir~variables predictoras,datos,)
lmcars<-lm(speed~dist,data=cars)
lmcars
#un modelo lineal tiene muchos atributos ocultos: lmcars$+tab (coeficientes, residuos y fit.values son los que vamos a ver)
require(ggplot2)
ggplot(lmcars)
ggplot(lmcars$coefficients)
ggplot(lmcars$coefficients)
ggplot help()
help("ggplot")
ggplot(cars)
install.packages("ggplot2")
install.packages("ggplot2")
ggplot(cars)
lmcars$residuals
#los valores del modelo son: lmcars$
#variable a predecir es la distancia.
lmcars$fitted.values
#El valor real menos los residuos veberían darte los valore del modelo
speed
#El valor real menos los residuos veberían darte los valore del modelo
cars$speed-lmcars$residuals
lmcars$fitted.values
lmcars
#Probamos con otro dataset
mtcars
#calcularemos el tiempo que tarda en recorrer 1/4 de milla.
#en este caso usaremos más de una variable predictora
lmtcars<-lm(qsec~cyl+hp+wt,data=mtcars)
lmtcars
#aqui el modelo es: y=ax_1+bx_2+cx_3 el modelo correspondería un hiperplano
mean(mtcars~qsec)
#aqui el modelo es: y=ax_1+bx_2+cx_3 el modelo correspondería un hiperplano
mean(mtcars$qsec)
#Por cada unidad de cilindro disminuye 0.58
#un coeficiente es mas importante cuanto mas grande es su valor (mas peso), se pueden comparar coeficientes atendiendo a sus coeficiente.
summary(lmtcars)
#Cuantos mas datos mejor se estima el modelo.
#p_valores, al ser mas bajo mejor (mas asperiscos), el coef será mas significativo, es decir, importante.
#el coeficiente que más importancia tiene es hp en este caso
summary(mtcars$hp)
#vamos a ver si todo esto es verdad. Si se añade un nº al azar,¿ayudará a predecir mejor?
#NO, NO CONTIENE INFORMACION RELECVANTE ASÍ QUE NO DEBERÍA
nrow(mtcars)
mtcars$azar<-rnorm(32)
View(mtcars)
#creo otro modelo con esta variable
lmtcars2<-lm(qsec~cyl+hp+wt+azar,data=mtcars)
#creo otro modelo con esta variable
lmtcars2<-lm(qsec~cyl+hp+wt+azar,data=mtcars)
lmtcars2
summary(lmtcars2)
# ejemplo con VARIABLES COLINEALES (VARIABLES AUNQUE NO SEAN LA MISMA SE PARECEN MUCHO)
#en un mismo modelo competirían entre sí robandose varianza. Va parecer que no son tan buenas pero ambas lo son
mtcars$wt2<-mtcars$wt*10+5
# ejemplo con VARIABLES COLINEALES (VARIABLES AUNQUE NO SEAN LA MISMA SE PARECEN MUCHO)
#en un mismo modelo competirían entre sí robandose varianza. Va parecer que no son tan buenas pero ambas lo son
mtcars$wt2<-mtcars$wt*10+5+rnorm(32)
#realmente son la misma variable solo que alterada, su comportamiento debería ser lo mismo
#vamos a ver que pasa ahora
lmtcars3<-lm(qsec~cyl+hp+wt+wt2+azar,data=mtcars)
lmtcars3
summary(lmtcars2)
summary(lmtcars3)
#1.
anova(lmtcars2,lmtcars)
lmtcars0<-lm(qsec~cyl,data=mtcars)
anova(lmtcars,lmtcars0)
#estos dos modelos son distintos F=18,9 y nos quedariamos con el segundo.
#Forma automática:
help("step")
#AIC es para comparar modelos tanto anidados como no anidados(no se debría pero se usa)
step(lmtcars3,direction = "both",)
#AIC es para comparar modelos tanto anidados como no anidados(no se debría pero se usa)
step(lmtcars3,direction = "both")
#SI el AIC baja es mejor.
#podemos usar este método de tanto en modelos lineales como en modelos lineales generalizados.
step(lmtcars0,direction = "both")
step(lmtcars2,direction = "both")
names(lmcars)
AIC(lmcars)
logLik(lmcars)
#FORMAS DE HACER UN DIAGNOSTICO PARA VER SI SE HA HECHO BIEN EL MODELO
plot(lmtcars3)
library(ROCR)
install.packages("ROCR")
install.packages("caret")
library(ROCR)
library(caret)
#dummy variables: me creo una variable España y te pongo un 1 si eres español o un 0 si no, y así con el resto de paises.
#Estas variables dummy son lineales ya que entre dos puntos (o un 1 o un 0) sólo hay lineas.
#En R y en mtcars, am es una variable cualitativa (ya es una dummy por si sola) y tal y como está ya podríamos meterla en el modelo
lmtcars4<-lm(qsec~hp+cyl+wt+am,data=mtcars)
summary(mtcars$mpg)
#agrupamos según su valor definiendo intervalos, si están por debajo de 15, 2, si están por encima de 15 y debajo de 22 1, y si está por encima de 22 0.
mtcars$mpg_cualitativa<-(mtcars$mpg<15) +(mtcars$mpg<22)
#agrupamos según su valor definiendo intervalos, si están por debajo de 15, 2, si están por encima de 15 y debajo de 22 1, y si está por encima de 22 0.
mtcars$mpg_cualitativa<-as.factor((mtcars$mpg<15) +(mtcars$mpg<22))
lmtcars_cualitativa<-lm(qsec~mpg_cualitativa+hp,data=mtcars)
summary(lmtcars_cualitativa)
#Usar variables cualitativas en las variables a predecir--> para eso hay que usar GLMs
summary(lmtcars)
#ejemplo titanic
Titanic
library(titanic)
install.packages("titanic")
library(titanic)
#se usa regresion logaritmica pq hay una gran conexion entre las variables categóricas.
#primer modelo.
#lo que quiero usar es titanic_train en verdad, para entrenar el modelo.
head(titanic_train)
#primer modelo:
titanic0<-glm(Survived~Age,data=titanic_train)
#primer modelo:
titanic0<-glm(Survived~Age,data=titanic_train)
titanic0
summary(titanic0)
#ha usado el lm normal, para ello
titanic0$family
#Hay que tener fundamentos en estadistica, (ver referencias de coursera y libros dados por Alejandro)
#vemos el parámetro family de glm. Se le especifica la distribucion y la funcion de enlace
titanic0<-glm(Survived~Age,data=titanic_train,family = gaussian(link="identity"))
titanic0$family
titanic1<-glm(Survived~Age,data=titanic_train,family = binomial(link="identity"))
titanic1$family
summary(titanic1)
titanic1<-glm(Survived~Age,data=titanic_train,family = binomial(link="identity"))
#la logistica solo puede hacer barreras lineales (solo puede expresarlas mediante una combinacion lineal estas, no curvas).
#vamos a usar una logit, en vez de identity
titanic1<-glm(Survived~Age,data=titanic_train,family = binomial(link="logit"))
titanic1<-glm(Survived~Age,data=titanic_train,family = binomial(link="identity"))
#la logistica solo puede hacer barreras lineales (solo puede expresarlas mediante una combinacion lineal estas, no curvas).
#vamos a usar una logit, en vez de identity
titanic2<-glm(Survived~Age,data=titanic_train,family = binomial(link="logit"))
summary(titanic1)
#el AIC cuanto mas alto peor, y aqui vale 964.32
summary(titanic2)
#volviendo a los modelos, redefinimos con mas variables:
titanic2<-glm(Survived~Age+Pclass+Sex,data=titanic_train,family = binomial(link="logit"))
summary(titanic2)
#vemos como ha descendido el AIC. Vemos relaciones mucho mas potentees, la mortalidad depende mucho de la edad, no linealmente, pero tambien de la clase y del sexo.
#que Pclass sea -1.28 significa que a mayor nº de clase menor probabilidad de superv.
#sexmale indicaria 0 hombres, 1 mujeres. Un incremento en Sexmale es un deremento de la mortalidad. Tienes un 2.52 menos de probailidad de morir que el otro grupo.
#sale sexmale como es 0 o 1 y es dummy pero no Pclass, hay que transformarla en dummy.
#Cuando ya tienes mas de una variable, el efecto de los coeficientes depende de los demás.
#Ojo con confiar en que estos modelos pueden resolver cualquier cosa-->supuesto de aditividad: se van suponiendo cosas que hacen que algo coja mucho peso, pero en el mundo real no todo es aditivo, cuidado con esto.
#En estos casos el error no se mide con las distancias (como se hacia en los modelos anteiores)
#se usan matrices de confusion--> basicamente son porcentajes de error:
titanic2<-glm(Survived~Age+as.factor(Pclass)+Sex,data=titanic_train,family = binomial(link="logit"))
summary(titanic2)
titanic2$fitted.values
#pasar la combinacion lineal por la funcion de enlace minimiza el error.
#donde corto? fallece no fallece
misPredicciones=titanic2$fitted.values>0.5#serán los que sobreviven
misPredicciones
#Supniendo que estamos con el test en vez de con el train.
titanic_train$Survived
(misPredicciones*1)#para transformar true en 1 y false en 0
#comparamos
titanic_train$Survived==(misPredicciones*1)
mean(titanic_train$Survived==(misPredicciones*1))
#respuesta del modelo 0<respuesta<1
p<-titanic2$fitted.values
#p<-predict(titanic2,type="response",newdata=titanic_test)
library(ROCR)
#respuesta del modelo 0<respuesta<1
p<-titanic2$fitted.values
#Segunda manera:
p<-predict(titanic2,type="response")#sin el response, devuelve el combinador lineal.Pero esto es trampa pq estamos haciendo el training. Tenemos que hacerlo sobre el este, por ello usamos otro dataset de datos.
titanic_predictio<-prediction(p,titanic_train$Survived)#como p es del train voy a usar el train
titanic2
p
length(p)
length(titanic_train)
#imputacion de los valores nan pq si no da error
titanic_train$Age[is.na(titanic_train$Age)]<-mean(titanic_train$Age, na.rm=TRUE)
titanic_train$Age[is.na(titanic_train$Age)]
titanic2<-glm(Survived~Age+as.factor(Pclass)+Sex,data=titanic_train,family = binomial(link="logit"))
#vuelvo a predecir:
p<-titanic2$fitted.values
titanic_prediction<-prediction(p,titanic_train$Survived)
plot(performance(titanic_prediction,measure="tpr",x.measure = "fpr"))
c=("glmnet","e1071")
c=["glmnet","e1071"]
c<-["glmnet","e1071"]
c<-("glmnet","e1071")
install.packages("glmnet")
install.packages("e1071")
#hay muchas formas de medir un estadistico pero todas estan basadas en la tabla de confusion (acierto fallo).
#pero el precio del coste lo determina el usuario, el modelo no lo sabe
#para el auc (área bajo la curva) otro indicador como el ROC
performance(titanic_prediction,measure="auc")
#hay muchas formas de medir un estadistico pero todas estan basadas en la tabla de confusion (acierto fallo).
#pero el precio del coste lo determina el usuario, el modelo no lo sabe.
#para ver el punto de corte vemos los alpha values que son los cutoff:
performance(titanic_prediction,measure="tpr",x.measure = "fpr")
#hay muchas formas de medir un estadistico pero todas estan basadas en la tabla de confusion (acierto fallo).
#pero el precio del coste lo determina el usuario, el modelo no lo sabe.
#para ver el punto de corte vemos los alpha values que son los cutoff:
k<-performance(titanic_prediction,measure="tpr",x.measure = "fpr")
k@alpha.name
#k es un objeto especial que tiene slots. Para acceder a los slots @. [[1]] indica que es una lista
l<-k@x.name[[1]]
l
k@x.name[[1]]
#k es un objeto especial que tiene slots. Para acceder a los slots @. [[1]] indica que es una lista
l<-k@x.name[1]
l
k
#k es un objeto especial que tiene slots. Para acceder a los slots @. [[1]] indica que es una lista
str(k@x.name[[1]])
l<-k@x.name[[1]]
l
l<-k@x.name[[[1]]]
max(which(l<0.2))
k@alpha.values[[1]][1]
l<-k@x.name
l
max(which(l<0.2))
max(which(l>0.2))
k@alpha.values[[1]][1]
k
